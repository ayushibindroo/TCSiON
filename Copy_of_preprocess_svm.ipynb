{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of preprocess svm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUKknjnZAnFVplVoKG98hX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushibindroo/TCSiON/blob/main/Copy_of_preprocess_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKMendrZCX7d"
      },
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "#load dataset\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "(train_X,train_Y),(test_X,test_Y)= fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "\n",
        "    (train_X,train_Y),(test_X,test_Y)= fashion_mnist.load_data()\n",
        "\n",
        "# Prepare the training images\n",
        "    train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
        "\n",
        "# Prepare the test images\n",
        "    test_X = test_X.reshape((test_X.shape[0], 28, 28, 1))\n",
        "\n",
        "#changing label to categorical data\n",
        "    train_Y= to_categorical(train_Y)\n",
        "    test_Y= to_categorical(test_Y)\n",
        "    return train_X,train_Y,test_X,test_Y\n",
        "\n",
        "np.unique(train_Y)\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "seed=9\n",
        "data_split= StratifiedShuffleSplit(test_size=0.5 ,random_state=seed)\n",
        "for train_index, test_index in data_split.split(train_X,train_Y):\n",
        "    split_data_92,split_data_8 = train_X[train_index], train_X[test_index]\n",
        "    split_label_92,split_label_8 = train_Y[train_index], train_Y[test_index]\n",
        "train_test_split= StratifiedShuffleSplit(test_size=0.3 ,random_state=seed)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(train_X[0])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "for train_index, test_index in train_test_split.split(split_data_8, split_label_8):\n",
        "    train_data_70, test_data_30= split_data_8[train_index], split_data_8[test_index]\n",
        "    train_label_70, test_label_30= split_label_8[train_index], split_label_8[test_index]\n",
        "train_data= train_data_70\n",
        "train_labels= train_label_70\n",
        "test_data= test_data_30\n",
        "test_labels= test_label_30\n",
        "print('train_data', train_data.shape)\n",
        "print('train_labels', train_labels.shape)\n",
        "print('test_data', test_data.shape)\n",
        "print('test_labels', test_labels.shape)\n",
        "\n",
        "\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#NORMALISATION\n",
        "train_data= train_data.astype('float64') / 255.0\n",
        "test_data= test_data.astype('float64') / 255.0\n",
        "\n",
        "#zca analysis\n",
        "train_data_flat= train_data.reshape(train_data.shape[0],-1)\n",
        "test_data_flat= test_data.reshape(test_data.shape[0],-1)\n",
        "print('train_data_flat', train_data_flat.shape)\n",
        "print('test_data_flat', test_data_flat.shape)\n",
        "train_data_flat_t= train_data_flat\n",
        "test_data_flat_t= test_data_flat\n",
        "       \n",
        "\n",
        "#pca\n",
        "from sklearn.decomposition import PCA\n",
        "train_data_pca= PCA(n_components= min(train_data_flat.shape)).fit_transform(train_data_flat)\n",
        "test_data_pca= PCA(n_components= min(test_data_flat.shape)).fit_transform(test_data_flat)\n",
        "print(train_data_pca.shape)\n",
        "print(test_data_pca.shape)\n",
        "\n",
        "\n",
        "#svd\n",
        "import skimage \n",
        "print(skimage.__version__)\n",
        "\n",
        "from skimage import color\n",
        "def svdFeatures(input_data):\n",
        "    svdArray_input_data= []\n",
        "    size= input_data.shape[0]\n",
        "    for i in range(0,size):\n",
        "        U,s,V= np.linalg.svd(input_data[i],full_matrices=False)\n",
        "        S=[s[i]for i in range(28)]\n",
        "        svdArray_input_data.append(S)\n",
        "        svdMatrix_input_data= np.matrix(svdArray_input_data)\n",
        "    return svdMatrix_input_data\n",
        "train_data_svd= svdFeatures(train_data)\n",
        "test_data_svd= svdFeatures(test_data)\n",
        "print(train_data_svd.shape)\n",
        "print(test_data_svd.shape)\n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}